#### LECTURE 2 ####

# Welcome to the course. This course will teach you how to conduct Exploratory Data Analyses using R Studio. In today's lecture, our goals are (1) to introduce you to the R studio environment, (2) teach you about Packages, libraries, objects, and functions, and (3) teach you how to load, view, merge, and susbet dataframes. 

# By default, R Studio displays four windows. In the top left, you have the Script Editor. The script editor is where you write and edit your code. In the top right, you have the environment window. The environment window is where objects, such as a data frame, are stored. In the bottom left, you have the R console. The R console shows you what code you have run, results from your code, and error messages. In the bottom right, you have a multi-purpose window. In the multi-purpose window, you can identify files you are working with, view plots and graphs generated by your code, identify packages that are currently installed and ready for use, review help documentation, and browse the web in the viewer pane.

# In this window, you can see that each paragraph of text begins with a hashtag (i.e., #). This symbol is used to add comments. Comments are not processed as code. Placing a hashtag at the beginning of a line of code means it will not be run. In this course, you are required to comment your code carefully so it is clear to others what you are trying to do when you are coding. This may seem like a nuisance, but it is a good very good habit to establish. 

# The lectures and assignments for this course will utilize data from the 2021 Canadian Social Connection Survey (CSCS). The CSCS is a serial cross-sectional survey with a longitudinal sub-cohort that aims to study the social health and wellbeing of Canadians in the wake of the COVID-19 pandemic. Data from Wave 1 of the CSCS was collected between April 21st, 2021 and June 1st, 2021, during the third wave of the COVID-19 Pandemic in Canada. Throughout this period, participants were recruited using paid advertising in French and English on Facebook, Twitter, Instagram, and Google. Advertisements were targeted to people aged 16 years of age or older across Canada.  Participants were eligible to participate if they were 16 years of age or older, lived in Canada, were able to complete the survey in English or French,  and provided informed consent. Upon completion of the survey, participants were eligible to enter a prize draw for a $200 VISA gift card. Ethics review for the CSCS was conducted by the Research Ethics Board at the University of Victoria (Ethics Protocol Number 21-0115). The questionnaire for this dataset is in the file called "CSCS_Questionnaire.pdf" and the question text and variable names are cross indexed in the file called: "variable_labels.csv". 

# Now that you've had a chance to review the CSCS support files, lets start learning to code in, by reading in the CSCS data. To do so you will have to copy the file path where your data is located. If you are using a windows computer, RIGHT-CLICK on the file while holding down the SHIFT key and select "COPY AS PATH." You can then come to this window and press CTRL+V to paste the file path. If you are using a mac computer, Click on the file while holding down the "CONTROL" button and press the "OPTION" key. When you press the option key, you will see "Copy" turn into "Copy [file path name] as Pathname". Select "Copy [file path name] as Pathname." You can then come to this window and press COMMAND+V to paste the file path. 

# On my computer, the CSCS data file is stored at the following path. It is important to recognize that R is case sensitive, so it is important that everything is copied exactly as they are stored: 
## "C:\Users\Kiffer\Google Drive\Work\2. Current Projects\HSCI_410\Lectures\CSCS_data.csv"

# The backslash is a special character in R. It suppressess the special meaning of the character it proceeds. Therefore, to turn the file path into a usable path, you must replace each backslash with a double backslash, as follows:
## "C:\\Users\\Kiffer\\Google Drive\\Work\\2. Current Projects\\HSCI_410\\Lectures\\CSCS_data.csv"

#Now that you have the file path ready, we need to write a command so that R knows what to do with the file path we created. R is a object-based programming language. We therefore write commands that assign values to objects. An example of an object is a data file. To assign the data file located at the file path above to an object, I will use the assignment operator: <- to create an object called "CSCS_data" that links to the file path I created. To help R accomplish this task, I also need to use the read.csv() function, which tells R what to do with the file path. read.csv(). 

CSCS_data <- read.csv(file = "C:\\Users\\Kiffer\\Google Drive\\Work\\2. Current Projects\\HSCI_410\\3. Lectures\\CSCS_data.csv", na.strings = c(" ", "", "NA", "9999: Missing")) #This command creates an object called "CSCS_data" using the read.csv() function. We have used two arguments within this function to specify the file name and the character strings that should be read in as missing.

#Within the read.csv() function, you can see that I have provided two arguments: "file = " and "na.strings = ". Arguments are options that you can use to clarify how you want the function to perform its job. Each argument is seperated by a comma. To understand what these arguments do, you can retrieve help documentation on any function, by using typing the ? symbol and the function name, as follows:

?read.csv #Using the ? in front of a function name opens the help file for that function

#If you scroll through the help file you will see sections on usage and arguments. These sections tell you what the arguments do. The "file = " argument is "the name of the file which the data are to be read from. In this case I am reading the file from a file path, which I have provided within quotation marks. The "na.strings = " argument is a character vector of strings which are interpreted as NA. I have created a list using the c() function. The c() function creates a vector. A vector is a single entitity consisting of a collection of things. In my case I have created a collection of character strings. Each character string is seperated by a comma and surrounded with quotation marks to indicate that they are strings and not objects. The string in this list says that if the data has a cell that is blank, a single space, NA, or says 9999: Missing, that the data should be read in as missing. You could add other character strings in this list, depending on how missing values are stored in the dataset you are reading in.  

##Instead of copying file paths, you can also set a working directory, which tells R where you are working from. To do so you use the setwd() function. If you set a working directory, you can refer to filese by name rather than copying their entire file path.
setwd("C:\\Users\\Kiffer\\Google Drive\\Work\\2. Current Projects\\HSCI_410\\3. Lectures\\")

#You can see that after running the command lines above, that the data object has now been added to your  environment window in the top right. Next to the object name, it shows the text "2448 obs. of 408 variables." This indicates that there are 2448 rows of data and 408 columns. Each column is a variable. Each row is a participant observation. You can click on the data object and view the spreadsheet you read in. 

#You can also view the CSCS_data using the view() command:
View(CSCS_data) #The View function will open the object called "CSCS_data" in a new window. Note that the View() function is typed with a capital V. If you were to use a lowercase V it would not work.

#Note that above we read in a .csv file using the read.csv() function. Different data types require using different functions. R includes many functions in its base package. However some functions require you to install a new package. Let's explore reading in a .xlsx file. To do so we will first need to install a package that contains a function that allows us to do this. While beyond the scope of this course, there are other functions and packages for other data file types that work very similar to those covered here. You can usually google and find an appropriate function that suits your specific needs. For example read.spss() is a function that can be used to open SPSS files and read_sas() can be used to open SAS files. Once you have identified a function and package, you often need to install a package so that it can be used. To do so, you can use the install.packages() function. Lets take a look at the help file for this function. 

?install.packages #Using the ? to open help documentation for the install.packages() function.

#The install.packages() function has an argument called pkgs. We can use this argument to specify the name of the package we want to download. In our case we want the readxl package

install.packages(pkgs = "readxl") #Installing the readxl package using the install.packages() function.

#Before an installed package can be used, you need to tell R that you are using a specific language library. This is because some functions have the same name as functions in other packages. To tell R we are using the readxl library we can use the library() function
library(readxl) #Telling R I want to use the readxl library

# We are now able to read in .xlsx data using the read_xlsx() function. Lets try this with the forward sortation area census data file. If you need to figure out how to use this function or if it ends up not working as expected, remember you can retrieve help documentation by typing the ? in front of the package name. Also, please note in some cases, when working with one package, you may need to update it or one of its dependent packages using the update.packages() function. For example if the read_xlsx() function does not work, you may need to update the readxl package or the Rcpp package. If this is the case, you will often get an error. When you recieve an error, you may have to search around the interent to find explanations or solutions that other users have come up with. Stackoverflow and Stackexchange are great Q&A websites that R users actively use to discuss errors. You can frequently find answers using those platforms. 

update.packages("readxl")
update.packages("Rcpp")

census_data <- read_xlsx(path = "census_data.xlsx", sheet = 1) #Using the read_xlsx() function, which is part of the readxl package to create an object called "census_data" from the first sheet of the .xlsx file. Notice that since I set up a working directory earlier, I did not need to copy the entire file path. I only needed the name of the file, which I found by going to the files tab in the bottom right window of R. 

#We now have two separate data files loaded in as R objects. The first object (i.e., CSCS_data) consists of survey responses. Each row represents a participant and each column a variable. The second object (i.e., census_data) consists of census data. Each row represents a forward sortation area (i.e., the first 3 letters of a postal code) and each column represents a variable. To use these two dataframes together, we will need to merge them. The merge() function is one function that can be used for this purpose. Lets review the help file for the merge function:

?merge #Review help documentation fir the merge() function

#As you can see, the merge function asks for two data frames or objects that you want to merge. You can merge these using a specific variable. If the variable you are mergine the data on is labeled differently in the two datasets, you can specify the variable names using the by.x and by.y arguments. In our case, we want to match forward sortation area level data for each participant using their self-reported FSA code. In both datasets this variable is labeled "FSA". Therefore we can use the by = argument. There is also another set of arguments that indicate what you should do in cases where there are not matches between the two datasets. For example, in our case we might not have recruited participants in every postal area. Also, not all participants provided a postal code. To ensure we keep all the participants in our survey, regardless of whether they have a matching postal code, we will use the all.x = TRUE argument. Because we don't want to create new rows for postal codes that dont have any participants living in them, we will also use the all.y = FALSE argument. Lets try merging the dataframes together using merge 
merged_data <- merge(x = CSCS_data, y = census_data, by = "FSA", all.x = TRUE, all.y = FALSE) #Merge CSCS_data and census_data to create merged_data

#You can see that the new variable has 2,448 observations (1 for each participant) and 485 variables (80 from the census_data and 406 from the CSCS_data). Because the FSA variable matched in the two datasets, you have 485 variables in the new merged_data file instead of 486. You can review the names of the columns and rows, using the colnames() and rownames() function. 

colnames(x = merged_data) #print names of columns
rownames(x = merged_data) #print names of rows

#As you can see there are lots of columns that you might not be interested in working with. It is sometimes helpful and sometimes necessary to create a data file that contains only the variables you want to work with. Likewise, there may be specific observations that you are interested in. To omit rows or columns you do not want to work with it is important to know how to subset a data file. 

#The [] symbol provides an easy way to subset your data so that it only includes specific observations or rows from your dataset. Lets create a dataset for each gender. Before we do, however, it is necessary to take a closer look at the gender variable in R. In R, you can call up data about a specific variable by using the $ symbol following your call for the dataframe. So in this example we would call the variable by specifying the name of the data frame, followed by the $ symbol, followed by the name of the gender variable: 

merged_data$gender #Print the gender column in the merged_data dataframe

#As you can see, it is difficult to make sense of the large volume of data displayed using the command above. There are three helpful functions that you can use to better understand the nature of a variable you are working with: class(), levels() and table(). Lets start with the class variable:

class(x = merged_data$gender) #tells you the class of the variable you are working with.

#As you can see the gender variable is currently stored as a character variable. Data can be stored as character, numbers, factors, as true/false logical values, or some other structure. Different functions specify what types of variables they can work with. For example, lets look at the help documentation for the levels() function:

?levels #retrieve help file for the levels() function.

#As you can see the levels function can be used on factors. Currently the gender variable in our dataset is stored as a character variable. We can change it to a factor variable using the as.factor() function. Other similar functions include the as.character(), as.logical(), as.integer(), and as.numeric() functions which can be used to set a variable type to character, logical, integer, or numeric. 

merged_data$gender <- as.factor(x = merged_data$gender) #replace the gender variable with a factor variable representing the same data.
class(x = merged_data$gender) #Confirm that the gender variable is now a factor.

#You can now run the levels function to identify levels() of the factor 
levels(x = merged_data$gender)

#The levels() function shows that there are three levels: "Man", "Non-binary", and "Woman" You can use the table() function to see how many of the 2448 participants identify as each gender. Notice that I include the useNA = argument to show the number of missing observations for the gender variable. 

table(merged_data$gender, useNA = "always") #create a frequency table for the gender variable. 

#Using the output from the functions above, we are now ready to subset our dataset using the [] symbol. To do so, we will create three datasets called "data_men", "data_women", and "data_nonbinary". Notice that to accomplish this we specify the source data (i.e., merged_data) and then add the bracket symbol immediately thereafter. The [] symbols can be used to specify a subset. I often read them as "where..." Within the [] symbol we then write a statement for each dataset that indicates which observations we want included in the new dataset. In doing so, we use the == sign to indicate "equals". You will also notice that following our statement there is a comma. When using the [] symbols, information prior to the comma specifies information about rows, and information following the comma specifies information about columns. 

data_men <- merged_data[merged_data$gender == "Man" ,]
data_women <- merged_data[merged_data$gender == "Non-binary" ,]
data_nonbinary <- merged_data[merged_data$gender == "Woman" ,]

#You can now use the table statement on the original dataset to ensure that the correct number of observations are stored in each of the new data files. 

table(merged_data$gender, useNA = "always") #confirm that the number of observations listed in the environment window matches what we expected from the original dataset.

#Now that you have a dataset for each gender, lets try creating a dataset that includes only a small subset of variables that we're interested in working with. In this case, I would like to only include variables included in the Malach-Pines Burnout Measure. To do this, I create an object called keepvars that includes a list of the names of the relevant variables I want to keep. 

keepvars <- c("burnout_tired",
              "burnout_disappointed",
              "burnout_hopeless",
              "burnout_trapped",
              "burnout_helpless",
              "burnout_depressed",
              "burnout_sick",
              "burnout_worthless",
              "burnout_difficulty_sleeping",
              "burnout_had_it") #Creates a list of variable names and stores it as an object called "keepvars"

#Using this newly created object, which represents a list of variable names, I will use the [] symbols to create a new dataset called "data_men_burnout_vars" that only contains these variables. Because I am referring to column names within the "data_men" dataframe, I am using the names() function in combination with the %in% function, which indicates "in". So you might read the code below as "create an object called 'data_men_burnout_vars' from the "data_men" dataframe where, the column's names are in the keepvars object."

data_men_burnout_vars <- data_men[, names(data_men) %in% keepvars] #create a new dataset called "data_men_burnout_vars" that only contains variables that are listed in the keepvars object

#If you wanted to create a dataset that did included all variables, except those listed variables, you could create a similar list, which I will instead call "dropvars." This name is arbitrary (and I could have in fact used the same object--keepvars--from above), but descriptive names are helpful. 

dropvars <- c("burnout_tired",
              "burnout_disappointed",
              "burnout_hopeless",
              "burnout_trapped",
              "burnout_helpless",
              "burnout_depressed",
              "burnout_sick",
              "burnout_worthless",
              "burnout_difficulty_sleeping",
              "burnout_had_it") #Creates a list of variable names and stores it as an object called "dropvars"

#To drop the variables contained in the "dropvars" list, I again use the brackets function. This time, I use the !() function  to tell R that I don't want these variables. In R, the exclamation symbol indicates "NOT".

data_men_no_burnout_vars <- data_men[,!(names(data_men) %in% dropvars)] #create a new dataset called "data_men_no_burnout_vars" that contains variables that are NOT listed in the "dropvars" object

#In today's lecture, we (1) introduced you to the R studio environment, (2) taught you about Packages, libraries, objects, and functions, and (3) taught you how to load, view, merge, and susbet dataframes. 